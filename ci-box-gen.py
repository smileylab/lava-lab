#!/usr/bin/env python3
#
from __future__ import print_function
import os, sys, time
import subprocess
import yaml
import string
import socket
import shutil

# Defaults
configs_yaml = "ci-box-conf.yaml"
tokens_yaml = "ci-box-tokens.yaml"
baud_default = 115200
ser2net_port_start = 63001
ser2net_ports = {}
allowed_hosts_list = [ '"127.0.0.1","localhost"' ]
default_master = "lava-server"
default_slave = "lava-worker"
zmq_auth_genlist = None
configs = None

# Lava conmux template
template_conmux = string.Template("""
#
# auto-generated by ci-box-gen.py for ${board}
#
listener ${board}
application console '${board} console' 'exec sg dialout "cu-loop /dev/${board} ${baud}"'
""")

# Lava reload udev template for lava-worker
template_udev_reload_sh = string.Template("""
#!/bin/sh

#check for root
BEROOT=""
if [ $$(id -u) -ne 0 ];then
    BEROOT=${beroot}
fi
$$BEROOT rm /etc/udev/rules.d/*lava*rules
$$BEROOT cp udev/*lava*rules /etc/udev/rules.d/
$$BEROOT udevadm control --reload-rules || exit $$?
$$BEROOT udevadm trigger || exit $$?
""")

# Lava device jinja2 templates
template_device = string.Template("""{% extends '${devicetype}.jinja2' %}""")
template_device_conmux = string.Template("""{% set connection_command = 'conmux-console ${board}' %}""")
template_device_connection_command = string.Template("""#{% set connection_command = '${connection_command}' %}""")
template_device_pdu_generic = string.Template("""
{% set hard_reset_command = '${hard_reset_command}' %}
{% set power_off_command = '${power_off_command}' %}
{% set power_on_command = '${power_on_command}' %}
""")
template_device_ums_generic = string.Template("""
{% set uboot_mass_storage_device = '/dev/disk/by-id/${by_id}' %}
""")
template_device_ser2net = string.Template("""{% set connection_command = 'telnet 127.0.0.1 ${port}' %}""")
template_device_screen = string.Template("""{% set connection_command = 'ssh -o StrictHostKeyChecking=no -t root@127.0.0.1 "TERM=xterm screen -x ${board}"' %}""")

# LAVA external postgres DB server setting template
template_instance_conf = string.Template("""
LAVA_DB_USER="$dbuser"
LAVA_DB_SERVER="$dbhost"
LAVA_DB_PORT="$dbport"
LAVA_SYS_USER="lavaserver"
LAVA_DB_PASSWORD="$dbpassword"
LAVA_DB_NAME="$dbname"
LAVA_INSTANCE="default"
""")

# Lava system config setting template
template_settings_conf = string.Template("""
{
    "DEBUG": false,
    "STATICFILES_DIRS": [
        ["lava-server", "/usr/share/pyshared/lava_server/htdocs/"]
    ],
    "MEDIA_ROOT": "/var/lib/lava-server/default/media",
    "ARCHIVE_ROOT": "/var/lib/lava-server/default/archive",
    "STATIC_ROOT": "/usr/share/lava-server/static",
    "STATIC_URL": "/static/",
    "MOUNT_POINT": "/",
    "HTTPS_XML_RPC": false,
    "LOGIN_URL": "/accounts/login/",
    "LOGIN_REDIRECT_URL": "/",
    "ALLOWED_HOSTS": [ $allowed_hosts ],
    "CSRF_TRUSTED_ORIGINS": ["$lava_http_fqdn"],
    "CSRF_COOKIE_SECURE": $cookie_secure,
    "SESSION_COOKIE_SECURE": $session_cookie_secure,
    "SERVER_EMAIL": "$server_email",
    "EMAIL_HOST": "$email_host",
    "EMAIL_HOST_USER": "$email_host_user",
    "EMAIL_HOST_PASSWORD": "$email_host_password",
    "EMAIL_PORT": $email_port,
    "EMAIL_USE_TLS": $email_use_tls,
    "EMAIL_USE_SSL": $email_use_ssl,
    "EMAIL_BACKEND": "$email_backend"
}
""")

# Lava coordinator config setting template
template_lava_coordinator_conf = string.Template("""
{
    "port": 3079,
    "blocksize": 4096,
    "poll_delay": 3,
    "coordinator_hostname": "$masterurl"
}
""")

# Lava coordinator entrypoint sh template
template_coordinator_sh = string.Template("""
#!/bin/sh
echo "Start lava-coordinator..."
mkdir /run/lava-coordinator && chown lavaserver /run/lava-coordinator
start-stop-daemon --start --chuid lavaserver --background --exec /usr/bin/lava-coordinator -- --logfile=/var/log/lava-server/lava-coordinator.log
exit $$?
""")

template_makefile = string.Template("""
all: builders servers\n
builders:\n\tdocker-compose build ${builders}\n
servers:\n\tdocker-compose build ${dockers}\n
start:\n\t./udev_reload.sh && docker-compose up -d ${dockers} && sudo /home/lava/ci-box/docker-udev-tools/udev-forward.sh\n
stop:\n\tdocker-compose stop ${dockers} && sudo systemctl disable udev-forward.service\n
status:\n\tdocker-compose ps\n
clean:\n\tdocker-compose down\n
distclean:\n\tdocker-compose down\n\tdocker image rm ${containers}\n
.PHONY: all run start stop status restart clean distclean
""")

template_tftpd_config = string.Template("""
# /etc/default/tftpd-hpa
TFTP_USERNAME="tftp"
TFTP_DIRECTORY="/var/lib/lava/dispatcher/tmp/"
TFTP_ADDRESS="0.0.0.0:${port}"
TFTP_OPTIONS="--secure"
""")

template_lava_slave_config = string.Template("""
# /etc/dispatcher/lava-slave
# Configuration for lava-slave daemon

# URL to the master and the logger
MASTER_URL="tcp://${lava_master}:5556"
LOGGER_URL="tcp://${lava_master}:5555"

# Logging level should be uppercase (DEBUG, INFO, WARNING, ERROR)
# LOGLEVEL="DEBUG"

# Encryption
# If set, will activate encryption using the master public and the slave
# private keys
# ENCRYPT="--encrypt"
# MASTER_CERT="--master-cert /etc/lava-dispatcher/certificates.d/<master.key>"
# SLAVE_CERT="--slave-cert /etc/lava-dispatcher/certificates.d/<slave.key_secret>"

LOGFILE=/var/log/lava-dispatcher/lava-slave.log
""")

#
# utility functions
#
def dockcomp_add_device(dockcomp, worker_name, devicemap):
    if "devices" in dockcomp["services"][worker_name]:
        dc_devices = dockcomp["services"][worker_name]["devices"]
    else:
        dockcomp["services"][worker_name]["devices"] = []
        dc_devices = dockcomp["services"][worker_name]["devices"]
    for dmap in dc_devices:
        if dmap == devicemap:
            return
    dc_devices.append(devicemap)

def usage():
    print("{} [config.yaml]".format(sys.argv[0]))

#
# parsing functions
#
def parse_database(dockcomp, database):
    """
    Parse Postgresql Database Configurations from ci-box-conf.yaml
    """
    workdir = "./ci-box-postgres/docker-postgres"
    keywords_database = [ "version", "dbhost", "dbport", "dbuser", "dbpassword",
    "dbname", "ports", "volumes", "environment", "shm_size" ]
    for keyword in database:
        if not keyword in keywords_database:
            print("WARNING: unknown keyword {}".format(keyword))
    name = "postgres"
    print("Parsing {}".format(name))

    # configs to start postgresql:latest docker-container
    dockcomp["services"][name] = {}
    dockcomp["services"][name]["container_name"] = name
    dockcomp["services"][name]["hostname"] = name
    dockcomp["services"][name]["image"] = "tn/{}".format(name)
    # extends:
    #      file: ./ci-box-postgres/docker-postgres/docker-compose.yml
    #      service: postgres
    dockcomp["services"][name]["extends"] = {}
    dockcomp["services"][name]["extends"]["file"] = "{}/docker-compose.yml".format(workdir)
    dockcomp["services"][name]["extends"]["service"] = name
    # build: overriding some args settings
    dockcomp["services"][name]["build"] = {}
    dockcomp["services"][name]["build"]["context"] = workdir
    dockcomp["services"][name]["build"]["args"] = {}
    dockcomp["services"][name]["build"]["args"]["version"] = database["version"]
    dockcomp["services"][name]["build"]["args"]["dbhost"] = database["dbhost"]
    dockcomp["services"][name]["build"]["args"]["dbport"] = database["dbport"]
    dockcomp["services"][name]["build"]["args"]["dbuser"] = database["dbuser"]
    dockcomp["services"][name]["build"]["args"]["dbpassword"] = database["dbpassword"]
    dockcomp["services"][name]["build"]["args"]["dbname"] = database["dbname"]
    dockcomp["services"][name]["restart"] = "always"
    # docker-compose's usual ports, volumes and environment overrides
    if "ports" in database and isinstance(database["ports"], list) and len(database["ports"]) > 0:
        dockcomp["services"][name]["ports"] = database["ports"]
    else:
        dockcomp["services"][name]["ports"] = []
        dockcomp["services"][name]["ports"].append("{}:{}".format(database["dbport"],database["dbport"]))
    if "volumes" in database and isinstance(database["volumes"], list) and len(database["volumes"]) > 0:
        dockcomp["services"][name]["volumes"] = database["volumes"]
    if "environment" in database and isinstance(database["environment"], dict) and len(database["environment"]) > 0:
        dockcomp["services"][name]["environment"] = {}
        dockcomp["services"][name]["environment"].update(database["environment"])
    if "shm_size" in database and len(database["shm_size"]) > 0:
        dockcomp["services"][name]["shm_size"] = database["shm_size"]



def parse_master(dockcomp, index, master):
    """
    Parse LAVA Server Configurations from ci-box-conf.yaml
    """
    workdir = "./ci-box-lava-master/configs"
    keywords_master = [ "name", "version", "users", "groups", "tokens", "webadmin_https",
                        "persistent_db", "zmq_auth", "zmq_auth_key", "zmq_auth_key_secret",
                        "http_fqdn", "slave_keys", "slaveenv", "loglevel", "allowed_hosts",
                        "lava-coordinator", "smtp", "aliases", "ports", "volumes", "environment",
                        "extra_packages", "healthcheck_url" ]
    for keyword in master:
        if not keyword in keywords_master:
            print("WARNING: unknown keyword {}".format(keyword))
    # default_master is the default lava-master to host everything, default is the first master
    if index == 0:
         default_master = master["name"]
    name = "{}{}".format(master["name"], index) if default_master == master["name"] and index > 0 else master["name"]
    print("Parsing {}\n".format(name))

    # dump the udev_reload.sh script
    with open("./udev_reload.sh", 'w') as finstance:
        finstance.write(template_udev_reload_sh.substitute(beroot="sudo"))
    os.chmod("./udev_reload.sh", 0o755)

    # setup configs for docker-compose.yml to bring up the lava-server(s)
    dockcomp["services"][name] = {}
    dockcomp["services"][name]["container_name"] = name
    dockcomp["services"][name]["hostname"] = name
    dockcomp["services"][name]["image"] = "tn/{}".format(name)
    # extends:
    #      file: ./ci-box-lava-master/docker-compose.yml
    #      service: lava-server
    dockcomp["services"][name]["extends"] = {}
    dockcomp["services"][name]["extends"]["file"] = "./ci-box-lava-master/docker-compose.yml"
    dockcomp["services"][name]["extends"]["service"] = "lava-server"
    # build: overriding some args settings
    dockcomp["services"][name]["build"] = {}
    dockcomp["services"][name]["build"]["context"] = "./ci-box-lava-master"
    dockcomp["services"][name]["build"]["args"] = {}
    dockcomp["services"][name]["build"]["args"]["version"] = master["version"]
    if "aliases" in master:
        dockcomp["services"][name]["networks"] = {}
        dockcomp["services"][name]["networks"]["default"] = {}
        dockcomp["services"][name]["networks"]["default"]["aliases"] = []
        dockcomp["services"][name]["networks"]["default"]["aliases"].append(master["aliases"])
    if "extra_packages" in master:
        dockcomp["services"][name]["build"]["args"]["extra_packages"] = master["extra_packages"]
    dockcomp["services"][name]["restart"] = "always"
    if isinstance(master["ports"], list) and len(master["ports"]) > 0:
        dockcomp["services"][name]["ports"] = master["ports"]
    if isinstance(master["volumes"], list) and len(master["volumes"]) > 0:
        dockcomp["services"][name]["volumes"] = master["volumes"]
    if isinstance(master["environment"], dict) and len(master["environment"]) > 0:
        dockcomp["services"][name]["environment"] = {}
        dockcomp["services"][name]["environment"].update(master["environment"])

    # setup persistent postgresql db locally, (default False)
    # specify whether the postgres DB is persistent over reboot
    persistent_db = master["persistent_db"] if "persistent_db" in master else False
    if persistent_db:
        pg_volume_name = "pgdata_" + name
        dockcomp["services"][name]["volumes"].append(pg_volume_name + ":/var/lib/postgresql")
        dockcomp["services"][name]["volumes"].append("lava_job_output:/var/lib/lava-server/default/media/job-output/")
        dockcomp["volumes"] = {}
        dockcomp["volumes"][pg_volume_name] = {}
        dockcomp["volumes"]["lava_job_output"] = {}
    else:
        if "postgres" in dockcomp["services"]:
            with open ("{}/instance.conf".format(workdir), 'w') as finstance:
                finstance.write(template_instance_conf.substitute(
                    dbuser=dockcomp["services"]["postgres"]["build"]["args"]["dbuser"],
                    dbhost=dockcomp["services"]["postgres"]["build"]["args"]["dbhost"],
                    dbport=dockcomp["services"]["postgres"]["build"]["args"]["dbport"],
                    dbpassword=dockcomp["services"]["postgres"]["build"]["args"]["dbpassword"],
                    dbname=dockcomp["services"]["postgres"]["build"]["args"]["dbname"]
                ))
            with open ("{}/.pgpass".format(workdir), 'w') as fpass:
                fpass.write("{}:{}:{}:{}:{}".format(
                    dockcomp["services"]["postgres"]["build"]["args"]["dbhost"],
                    dockcomp["services"]["postgres"]["build"]["args"]["dbport"],
                    dockcomp["services"]["postgres"]["build"]["args"]["dbname"],
                    dockcomp["services"]["postgres"]["build"]["args"]["dbuser"],
                    dockcomp["services"]["postgres"]["build"]["args"]["dbpassword"],
                ))
            dockcomp["services"][name]["depends_on"] = []
            dockcomp["services"][name]["depends_on"].append("postgres")
        else:
            print("Error: no external database defined for non peristent_db for lava-master")
            sys.exit(1)

    # start lava-coordinator daemon in lava-master with a 99_lava-coordinator script
    # and listening on default port 3079 (for multiple worker nodes setups)
    if "lava-coordinator" in master and master["lava-coordinator"]:
        dockcomp["services"][name]["ports"].append('3079:3079')
        with open("./ci-box-lava-master/entrypoint.d/99_lava-coordinator.sh", 'w') as f_entrypoint:
            f_entrypoint.write(template_coordinator_sh.substitute({}))

    # Specify whether the LAVA webadmin is accessed via https
    if "webadmin_https" in master and master["webadmin_https"]:
        cookie_secure = "true"
        session_cookie_secure = "true"
    else:
        cookie_secure = "false"
        session_cookie_secure = "false"

    # setup fully qualified domain name for lava-master, and setup allowed host lists for Django settings.conf
    # This is necessary if you use https otherwise you will issue CSRF errors.
    if "http_fqdn" in master:
        lava_http_fqdn = master["http_fqdn"]
        allowed_hosts_list.append('"{}"'.format(lava_http_fqdn))
    else:
        lava_http_fqdn = "127.0.0.1"
    allowed_hosts_list.append('"{}"'.format(name))
    if "allowed_hosts" in master:
        for allow_host in master["allowed_hosts"]:
            allowed_hosts_list.append('"{}"'.format(allow_host))
    with open("{}/lava_http_fqdn".format(workdir), 'w') as f_fqdn:
        f_fqdn.write(lava_http_fqdn)

    # setup settings.conf for DJANGO defaults (used in lava-server i.e. /etc/lava-server)
    email_host = "localhost"
    email_host_user = ""
    email_host_password = ""
    email_port = 25
    email_use_tls = 'false'
    email_use_ssl = 'false'
    email_backend = 'django.core.mail.backends.smtp.EmailBackend'
    server_email = "root@localhost"
    if "smtp" in master:
        if "server_email" in master["smtp"]:
            server_email = master["smtp"]["server_email"]
        if "email_host" in master["smtp"]:
            email_host = master["smtp"]["email_host"]
        if "email_host_user" in master["smtp"]:
            email_host_user = master["smtp"]["email_host_user"]
        if "email_host_password" in master["smtp"]:
            email_host_password = master["smtp"]["email_host_password"]
        if "email_port" in master["smtp"]:
            email_port = master["smtp"]["email_port"]
        # django does not like True or False but want true/false (no upper case)
        if "email_use_tls" in master["smtp"]:
            email_use_tls = master["smtp"]["email_use_tls"]
            if isinstance(email_use_tls, bool):
                email_use_tls = 'true' if email_use_tls else 'false'
        if "email_use_ssl" in master["smtp"]:
            email_use_ssl = master["smtp"]["email_use_ssl"]
            if isinstance(email_use_ssl, bool):
                email_use_ssl = 'true' if email_use_ssl else 'false'
        if "email_backend" in master["smtp"]:
            email_backend = master["smtp"]["email_backend"]
    allowed_hosts = ','.join(allowed_hosts_list)   # A list of FQDN used to access the LAVA master
    with open("{}/settings.conf".format(workdir), 'w') as fsettings:
        fsettings.write(template_settings_conf.substitute(
            cookie_secure=cookie_secure,
            session_cookie_secure=session_cookie_secure,
            lava_http_fqdn=lava_http_fqdn,
            allowed_hosts=allowed_hosts,
            email_host = email_host,
            email_host_user = email_host_user,
            email_host_password = email_host_password,
            email_port = email_port,
            email_use_tls = email_use_tls,
            email_use_ssl = email_use_ssl,
            email_backend = email_backend,
            server_email = server_email
            )
        )

    # setting up the zero-message-queue between lava-server and lava-worker
    # zmq_auth True/False specify whether lava-master requires ZMQ authentication.
    # "zmq_auth_key" - specify the path to a public ZMQ key
    # "zmq_auth_key_secret" - specify the path to a private ZMQ key
    if "zmq_auth" in master and master["zmq_auth"]:
        if "zmq_auth_key" in master:
            shutil.copy(master["zmq_auth_key"], "{}/zmq_auth/{}.key".format(workdir, name))
            shutil.copy(master["zmq_auth_key_secret"], "{}/zmq_auth/{}.key_secret".format(workdir, name))
        else:
            zmq_auth_genlist.write("{}/{}\n".format(workdir, name))
            need_zmq_auth_gen = True
        # optional path to a directory with slaves public key.
        # Usefull when you want to create a lava-master without lava-slaves nodes in boards.yaml.
        if "slave_keys" in master:
            src_files = os.listdir(master["slave_keys"])
            for file_name in src_files:
                full_file_name = os.path.join(master["slave_keys"], file_name)
                shutil.copy(full_file_name, "{}/zmq_auth/".format(workdir))

    # setup groups for lava-sever
    # (in lava-master/groups/ folder)
    groupsdir = "{}/groups".format(workdir)
    os.mkdir(groupsdir)
    if "groups" in master:
        for group in master["groups"]:
            groupname = group["name"]
            print("\tAdding group {}".format(groupname))
            with open("{}/{}.group".format(groupsdir, groupname), "w") as fgrp:
                fgrp.write("GROUPNAME={}\n".format(groupname))
                submitter = False
                if "submitter" in group:
                    submitter = group["submitter"]
                if submitter:
                    fgrp.write("SUBMIT=1\n")

    # setup users for lava-server
    # (in lava-master/users/ folder)
    usersdir = "{}/users".format(workdir)
    os.mkdir(usersdir)
    if "users" in master:
        for user in master["users"]:
            keywords_users = [ "username", "password", "staff", "superuser", "token", "email", "groups" ]
            for keyword in user:
                if not keyword in keywords_users:
                    print("WARNING: unknown keyword {}".format(keyword))
            username = user["username"]
            with open("{}/{}".format(usersdir, username), "w") as ftok:
                if "token" in user:
                    token = user["token"]
                    ftok.write("TOKEN=" + token + "\n")
                if "password" in user:
                    password = user["password"]
                    ftok.write("PASSWORD=" + password + "\n")
                    # libyaml convert yes/no to true/false...
                if "email" in user:
                    email = user["email"]
                    ftok.write("EMAIL=" + email + "\n")
                if "staff" in user:
                    value = user["staff"]
                    if value is True:
                        ftok.write("STAFF=1\n")
                if "superuser" in user:
                    value = user["superuser"]
                    if value is True:
                        ftok.write("SUPERUSER=1\n")
            # setup user's group
            if "groups" in user:
                for group in user["groups"]:
                    groupname = group["name"]
                    print("\tAdd user {} to {}".format(username, groupname))
                    with open("{}/groups/{}.group.list".format(workdir, groupname), "a") as fgrp_userlist:
                        fgrp_userlist.write("{}\n".format(username))

    # A list of tokens to setup the LAVA users owning the token specified
    # users could be created via users, and the token is for 'this callback'
    # (in lava-master/tokens/ folder)
    tokensdir = "{}/tokens".format(workdir)
    os.mkdir(tokensdir)
    if "tokens" in master:
        filename_num = {}
        print("Found tokens")
        for token in master["tokens"]:
            keywords_tokens = [ "username", "token", "description" ]
            for keyword in token:
                if not keyword in keywords_tokens:
                    print("WARNING: unknown keyword {}".format(keyword))
            username = token["username"]
            description = token["description"]
            if username in filename_num:
                number = filename_num[username]
                filename_num[username] = filename_num[username] + 1
            else:
                filename_num[username] = 1
                number = 0
            filename = "{}-{}".format(username, number)
            print("\tAdd token for {} in {}".format(username, filename))
            with open("{}/{}".format(tokensdir, filename), "w") as ftok:
                ftok.write("USER=" + username + "\n")
                vtoken = token["token"]
                ftok.write("TOKEN=" + vtoken + "\n")
                ftok.write("DESCRIPTION=\"{}\"".format(description))

    # setup slaveenv for lava-sever, this generates a list of environment to pass to slave
    # (in lava-master/env/ folder)
    if "slaveenv" in master:
        for slaveenv in master["slaveenv"]:
            slavename = slaveenv["name"]
            envdir = "{}/env/{}".format(workdir, slavename)
            os.mkdir(envdir)
            with open("{}/env.yaml".format(envdir), 'w') as fenv:
                fenv.write("overrides:\n")
                for line in slaveenv["env"]:
                    fenv.write("  {}\n".format(line))

    # setup log levels for lave-master, lava-slave, lava-server-gunicorn, lava-logs
    # (in lava-master/defaults/ folder)
    if "loglevel" in master:
        for component in master["loglevel"]:
            if component != "lava-master" and component != "lava-logs" and component != 'lava-server-gunicorn':
                print("ERROR: invalid loglevel component {}".format(component))
                sys.exit(1)
            loglevel = master["loglevel"][component]
            if loglevel != 'DEBUG' and loglevel != 'INFO' and loglevel != 'WARN' and loglevel != 'ERROR':
                print("ERROR: invalid loglevel {} for {}".format(loglevel, component))
                sys.exit(1)
            with open("{}/default/{}".format(workdir, component), 'w') as fcomponent:
                fcomponent.write("LOGLEVEL={}\n".format(loglevel))

    # optional configs for specify healthcheck files/images server (include mainline build images)
    # for downloading, the healthcheck_url is examined by lava-master's Dockerfile,
    # and used to replace URL in container's etc/lava-server/dispatcher-config/health-checks/ files
    if "healthcheck_url" in master:
        # set to build args instead of writing to file
        #with open("{}/health-checks/healthcheck_url".format(workdir), 'w') as f_hc:
        #    f_hc.write(master["healthcheck_url"])
        dockcomp["services"][name]["build"]["args"]["healthcheck_url"] = master["healthcheck_url"]

    # devices folder for storing devices jinja2s files
    devicesdir = "{}/devices".format(workdir)
    os.mkdir(devicesdir)



def parse_slave(dockcomp, index, slave, masters):
    """
    Parse LAVA worker Configurations from ci-box-conf.yaml
    """
    workdir = "./ci-box-lava-worker/configs"
    keywords_slaves = [ "name", "version", "zmq_auth_key", "zmq_auth_key_secret", "zmq_auth_master_key",
    "dispatcher_ip", "remote_master", "remote_address", "remote_rpc_port", "remote_user",
    "remote_user_token", "remote_proto", "default_slave", "bind_dev",
    "use_tftp", "use_nbd", "use_overlay_server", "use_nfs", "use_tap",
    "arch", "lava-coordinator", "expose_ser2net", "expose_ports",
    "extra_actions", "extra_packages", "loglevel", "env", "tags", "devices",
    "ports", "volumes", "environment" ]
    for keyword in slave:
        if not keyword in keywords_slaves:
            print("WARNING: unknown keyword {}".format(keyword))
    # default_slave is the default lava-worker to add boards, default is the first slave
    if "default_slave" in slave and slave["default_slave"] or index == 0:
         default_slave = slave["name"]
    name = "{}{}".format(slave["name"], index) if default_slave == slave["name"] and index > 0 else slave["name"]
    print("Handle {}".format(name))

    dockcomp["services"][name] = {}
    dockcomp["services"][name]["container_name"] = name
    dockcomp["services"][name]["hostname"] = name
    dockcomp["services"][name]["image"] = "tn/{}".format(name)
    # extends:
    #      file: ./ci-box-lava-slave/docker-compose.yml
    #      service: lava-slave
    dockcomp["services"][name]["extends"] = {}
    dockcomp["services"][name]["extends"]["file"] = "./ci-box-lava-worker/docker-compose.yml"
    dockcomp["services"][name]["extends"]["service"] = "lava-worker"
    # build: overriding some args settings
    dockcomp["services"][name]["build"] = {}
    dockcomp["services"][name]["build"]["context"] = "./ci-box-lava-worker"
    dockcomp["services"][name]["build"]["args"] = {}
    dockcomp["services"][name]["build"]["args"]["version"] = slave["version"]
    if "extra_packages" in slave:
        dockcomp["services"][name]["build"]["args"]["extra_packages"] = slave["extra_packages"]
    dockcomp["services"][name]["dns_search"] = ""
    dockcomp["services"][name]["restart"] = "always"
    if "ports" in slave and isinstance(slave["ports"], list) and len(slave["ports"]) > 0:
        dockcomp["services"][name]["ports"] = slave["ports"]
    if "volumes" in slave and isinstance(slave["volumes"], list) and len(slave["volumes"]) > 0:
        dockcomp["services"][name]["volumes"] = slave["volumes"]
    if "environment" in slave and isinstance(slave["environment"], dict) and len(slave["environment"]) > 0:
        dockcomp["services"][name]["environment"] = {}
        dockcomp["services"][name]["environment"].update(slave["environment"])

    # using "local", which is used in setup.sh, i.e. add worker via lavacli
    # lavacli $LAVACLIOPTS workers add --description "LAVA dispatcher on $(cat /root/phyhostname)" $worker || exit $?
    with open("{}/phyhostname".format(workdir), "w") as fp:
        fp.write("local")

    # setup conmux folder conmux configs
    conmuxpath = "{}/conmux".format(workdir)
    if not os.path.isdir(conmuxpath):
        os.mkdir(conmuxpath)

    # the arch of the worker (if not x86_64), only accept arm64 which changes
    # lava-slave-base to lava-slave-base-arm64 from the Dockerfile
    # (but it does not contain any "lava-slave-base" strings)
    if "arch" in slave and slave["arch"] == 'arm64':
        with open("{}/Dockerfile".format(workdir), "r+") as dockerfile:
            dfcontent = dockerfile.read().replace("lava-slave-base", "lava-slave-base-arm64")
            dockerfile.seek(0)
            dockerfile.write(dfcontent)

    # the name of the master to connect to, i.e. which master to connect on slave
    remote_master = slave["remote_master"] if "remote_master" in slave else "lava-server"
    # the FQDN or IP address of the master (if different from remote_master)
    remote_address =  slave["remote_address"] if "remote_address" in slave else remote_master
    # the port used by the LAVA RPC2 (default 80)
    remote_rpc_port = slave["remote_rpc_port"] if "remote_rpc_port" in slave else "80"
    # the user used for connecting to the master
    remote_user = slave["remote_user"]

    #
    # set up slave configuration, i.e. /etc/lava-dispatcher/lava-slave
    #
    with open("{}/lava-slave".format(workdir), "w") as fslave:
        fslave.write(template_lava_slave_config.substitute(lava_master=remote_master))

    #
    # set up tokens for zmq to connect to lava-master
    #
    remote_token = "BAD"
    if isinstance(masters, list):
        # The remote_user's token. This option is necessary only no master node exists in boards.yaml.
        # Otherwise ci-box-gen.py will get from it.
        if "remote_user_token" in slave:
            remote_token = slave["remote_user_token"]
            if "zmq_auth_key" in slave:
                # optional path to a public ZMQ key
                shutil.copy(slave["zmq_auth_key"], "{}/zmq_auth/".format(workdir))
                # optional path to a private ZMQ key
                shutil.copy(slave["zmq_auth_key_secret"], "{}/zmq_auth/".format(workdir))
                # optional path to the public master ZMQ key.
                # This option is necessary only if no master node exists in boards.yaml.
                shutil.copy(slave["zmq_auth_master_key"], "{}/zmq_auth/".format(workdir))
    # look at master's zmq config
    slave_master = None
    for fm in masters:
        if fm["name"] == remote_master:
            slave_master = fm
            for fuser in fm["users"]:
                if fuser["username"] == remote_user:
                    remote_token = fuser["token"]
            master_use_zmq_auth = fm["zmq_auth"] if "zmq_auth" in fm else False
            if master_use_zmq_auth:
                if "zmq_auth_key" in fm:
                    shutil.copy(fm["zmq_auth_key"], "{}/zmq_auth/{}.key".format(workdir, remote_address))
                if "zmq_auth_key" in slave:
                    shutil.copy(slave["zmq_auth_key"], "{}/zmq_auth/{}.key".format(workdir, name))
                    shutil.copy(slave["zmq_auth_key_secret"], "{}/zmq_auth/{}.key_secret".format(workdir, name))
                    if "zmq_auth_key" in fm:
                        shutil.copy(slave["zmq_auth_key"], "output/{}/{}/zmq_auth/{}.key".format(fm["host"], fm["name"], name))
                else:
                    zmq_auth_genlist.write("{}/{} {}/{}\n".format(host, name, fm["host"], fm["name"]))
                    need_zmq_auth_gen = True

    if remote_token is "BAD":
        print("Cannot find {} on {}".format(remote_user, remote_master))
        sys.exit(1)

    if "env" in slave:
        if not slave_master:
            print("Cannot set env without master")
            sys.exit(1)
        envdir = "{}/env/{}".format(slave_master["name"], name)
        os.mkdir(envdir)
        with open("{}/env.yaml".format(envdir), 'w') as fenv:
            fenv.write("overrides:\n")
            for line in slave["env"]:
                fenv.write("  {}\n".format(line))

    # protocol used on remote: http(default) or https
    remote_proto = "http" if not "remote_proto" in slave else slave["remote_proto"]
    # construct the base URL for access the lava-master RPC2
    remote_uri = "{}://{}:{}@{}:{}/RPC2".format(remote_proto, remote_user, remote_token, remote_address, remote_rpc_port)
    dockcomp["services"][name]["environment"]["LAVA_MASTER"] = remote_address
    dockcomp["services"][name]["environment"]["LAVA_MASTER_URI"] = remote_uri
    dockcomp["services"][name]["environment"]["LAVA_MASTER_USER"] = remote_user
    dockcomp["services"][name]["environment"]["LAVA_MASTER_BASEURI"] = "{}://{}:{}/RPC2".format(remote_proto, remote_address, remote_rpc_port)
    dockcomp["services"][name]["environment"]["LAVA_MASTER_TOKEN"] = remote_token

    # setup lava-coordinator config in lava-worker, lava-coordinator.cnf will be renamed
    # to lava-coordinator.conf in lave-worker Dockerfile
    use_coordinator = slave["lava-coordinator"] if "lava-coordinator" in slave else False
    if use_coordinator:
        with open("{}/lava-coordinator/lava-coordinator.conf".format(workdir), 'w') as fcoordinator:
            fcoordinator.write(template_lava_coordinator_conf.substitute(masterurl=remote_address))

    if "dispatcher_ip" in slave:
        dispatcher_ip = slave["dispatcher_ip"]
        dockcomp["services"][name]["environment"]["LAVA_DISPATCHER_IP"] = dispatcher_ip
        # setup displatcher.yaml for dispatcher.d on lava-master
        if remote_master in dockcomp["services"]:
            envdir = "./ci-box-lava-master/configs/env/{}".format(name)
            if not os.path.exists(envdir):
                os.mkdir(envdir)
            with open("{}/dispatcher.yaml".format(envdir), 'w') as fenv:
                fenv.write("dispatcher_ip: {}\n".format(dispatcher_ip))
    else:
        dispatcher_ip = "0.0.0.0"

    if "expose_ports" in slave:
        for eports in slave["expose_ports"]:
            if not "ports" in dockcomp["services"][name]:
                dockcomp["services"][name]["ports"] = []
            dockcomp["services"][name]["ports"].append("{}".format(eports))

    # Bind /dev from host to slave. This is needed when lava-workers tries to
    # access some HID PDU on the host container os.
    if "bind_dev" in slave:
        if isinstance(slave["bind_dev"], bool) and slave["bind_dev"]:
            dockcomp["services"][name]["volumes"].append("/dev:/dev")
        elif isinstance(slave["bind_dev"], str) and len(slave["bind_dev"]) > 0:
            dockcomp["services"][name]["volumes"].append("{}:{}".format(slave["bind_dev"], slave["bind_dev"]))
        dockcomp["services"][name]["privileged"] = True

    # An optional list of actions to do at the end of the docker build
    # e.g. apt-get install package
    if "extra_actions" in slave:
        with open("{}/scripts/extra_actions".format(workdir), "w") as fp:
            for eaction in slave["extra_actions"]:
                fp.write(eaction)
                fp.write("\n")
        os.chmod("{}/scripts/extra_actions".format(workdir), 0o755)

    # A list of devices which need UDEV rules
    if "devices" in slave:
        if not os.path.isdir("./udev"):
            os.mkdir("./udev")
        for udev_dev in slave["devices"]:
            udev_line = 'SUBSYSTEM=="tty", ATTRS{idVendor}=="{:04x}", ATTRS{idProduct}=="{:04x}", '.format(udev_dev["idvendor"], udev_dev["idproduct"])
            if "serial" in udev_dev:
                udev_line += 'ATTRS{serial}=="{}", '.format(udev_dev["serial"])
            if "devpath" in udev_dev:
                udev_line += 'ATTRS{devpath}=="{}", '.format(udev_dev["devpath"])
            udev_line += 'MODE="0664", OWNER="uucp", SYMLINK+="{}"\n'.format(udev_dev["name"])
            with open("./udev/99-lavaworker-udev.rules", "a") as fudev:
                fudev.write(udev_line)
            # when no bind_dev specified for the container os host,
            # create own dev binding for the container so as to access the device on host
            if not ("bind_dev" in slave and isinstance(slave["bind_dev"], bool) and slave["bind_dev"]):
                dockcomp_add_device(dockcomp, name, "/dev/{}:/dev/{}".format(udev_dev["name"], udev_dev["name"]))

    # specify that lava uses a TFTP server
    use_tftp = slave["use_tftp"] if "use_tftp" in slave else True
    if use_tftp:
        if not "ports" in dockcomp["services"][name]:
            dockcomp["services"][name]["ports"] = []
        dockcomp["services"][name]["ports"].append("69:69/udp")
        # dump tftpd-hpa config file
        with open("{}/tftpd-hpa".format(workdir), "w") as ftftpd:
            ftftpd.write(template_tftpd_config.substitute(port="69"))

    # specify that lava uses a NBD server
    # TODO permit to change the range of NBD ports
    use_nbd = slave["use_nbd"] if "use_nbd" in slave else True
    if use_nbd:
        if not "ports" in dockcomp["services"][name]:
            dockcomp["services"][name]["ports"] = []
        dockcomp["services"][name]["ports"].append("61950-62000:61950-62000")

    # specify that lava uses an overlay server
    use_overlay_server = slave["use_overlay_server"] if "use_overlay_server" in slave else True
    if use_overlay_server:
        if not "ports" in dockcomp["services"][name]:
            dockcomp["services"][name]["ports"] = []
        dockcomp["services"][name]["ports"].append("80:80")

    # specify that lava dispatcher could run NFS jobs
    use_nfs = slave["use_nfs"] if "use_nfs" in slave else False
    if use_nfs:
        dockcomp["services"][name]["volumes"].append("/var/lib/lava/dispatcher/tmp:/var/lib/lava/dispatcher/tmp")
        with open("{}/scripts/extra_actions".format(workdir), "a") as fp:
            fp.write("apt-get -y install nfs-kernel-server\n")
        os.chmod("{}/scripts/extra_actions".format(workdir), 0o755)

    # specify that lava could use TAP netdevices
    use_tap = slave["use_tap"] if "use_tap" in slave else False
    if use_tap:
        dockcomp_add_device(dockcomp, name, "/dev/net/tun:/dev/net/tun")
        dockcomp["services"][name]["cap_add"] = []
        dockcomp["services"][name]["cap_add"].append("NET_ADMIN")

    if "loglevel" in slave:
        for component in slave["loglevel"]:
            if component != "lava-slave":
                print("ERROR: invalid loglevel component {}".format(component))
                sys.exit(1)
            loglevel = slave["loglevel"][component]
            if loglevel != 'DEBUG' and loglevel != 'INFO' and loglevel != 'WARN' and loglevel != 'ERROR':
                print("ERROR: invalid loglevel {} for {}".format(loglevel, component))
                sys.exit(1)
            with open("{}/default/{}".format(workdir, component), 'w') as fcomponent:
                fcomponent.write("LOGLEVEL={}\n".format(loglevel))



def parse_board(dockcomp, board, slaves):
    """
    Parse LAVA worker Configurations from ci-box-conf.yaml
    """
    board_name = board["name"]
    if "slave" in board:
        worker_name = board["slave"]
    else:
        print("{} config must specify a belonging slave".format(worker_name))
        sys.exit(1)
    print("\tFound {} for {}".format(board_name, worker_name))

    slave = None
    for index, fs in enumerate(slaves, start=0):
        if fs["name"] == worker_name:
            slave = fs
            slave_name = worker_name
            break
    if slave is None:
        print("Cannot find slave {}".format(worker_name))
        sys.exit(1)

    workdir = "./ci-box-lava-worker/configs"
    device_basepath = "{}/devices/".format(workdir)
    devices_workerpath = "{}/devices/{}".format(workdir, slave_name)
    devicetype = board["type"]
    device_line = template_device.substitute(devicetype=devicetype)
    if "pdu_generic" in board:
        hard_reset_command = board["pdu_generic"]["hard_reset_command"]
        power_off_command = board["pdu_generic"]["power_off_command"]
        power_on_command = board["pdu_generic"]["power_on_command"]
        device_line += template_device_pdu_generic.substitute(
                        hard_reset_command=hard_reset_command,
                        power_off_command=power_off_command,
                        power_on_command=power_on_command
                    )
    if "ums" in board:
        # ACTION=="add", ENV{ID_SERIAL_SHORT}=="E00A1029", RUN+="/usr/local/bin/usb-passthrough -a -d %E{ID_SERIAL_SHORT} -i lava-dispatcher"
        serial = board["ums"]["serial"]
        idvendor = board["ums"]["idvendor"]
        idproduct = board["ums"]["idproduct"]
        serial_short = board["ums"]["serial_short"]
        udev_line = "ACTION==\"add\", ENV{{ID_SERIAL_SHORT}}==\"{}\", RUN+=\"/home/lava/ci-box/docker-udev-tools/usb-passthrough -a -d %E{{ID_SERIAL_SHORT}} -i lava-worker\"\n".format(serial_short)
        if not os.path.isdir("./udev"):
            os.mkdir("./udev")
        with open("./udev/99-lavaworker-udev.rules", "a") as fp:
            fp.write(udev_line)
        device_line += template_device_ums_generic.substitute(by_id=serial)
    use_kvm = board["kvm"] if "kvm" in board else False
    if use_kvm:
        dockcomp_add_device(dockcomp, slave_name, "/dev/kvm:/dev/kvm")

    # board specific hacks
    if devicetype == "qemu" and not use_kvm:
        device_line += "{{% set no_kvm = True %}}\n"

    # setup serial communications config with the target DUT board
    if "uart" in board:
        # setup the serial interface of the target DUT board for udev rules
        uart = board["uart"]
        baud = board["uart"]["baud"] if "baud" in board["uart"] else baud_default
        idvendor = board["uart"]["idvendor"]
        idproduct = board["uart"]["idproduct"]
        if isinstance(idproduct, str):
            print("Please put hexadecimal IDs for product {} (like 0x{})".format(board_name, idproduct))
            sys.exit(1)
        if isinstance(idvendor, str):
            print("Please put hexadecimal IDs for vendor {} (like 0x{})".format(board_name, idvendor))
            sys.exit(1)
        udev_line = "SUBSYSTEM==\"tty\", ATTRS{{idVendor}}==\"{:04x}\", ATTRS{{idProduct}}==\"{:04x}\", ".format(idvendor, idproduct)
        if "serial" in uart:
            udev_line += "ATTRS{{serial}}==\"{}\", ".format(board["uart"]["serial"])
        if "devpath" in uart:
            udev_line += "ATTRS{{devpath}}==\"{}\", ".format(board["uart"]["devpath"])
        if "interfacenum" in uart:
            udev_line += "ENV{{ID_USB_INTERFACE_NUM}}==\"{}\", ".format(board["uart"]["interfacenum"])
        udev_line += "MODE=\"0664\", OWNER=\"uucp\", SYMLINK+=\"{}\"\n".format(board_name)
        if not os.path.isdir("./udev"):
            os.mkdir("./udev")
        with open("./udev/99-lavaworker-udev.rules", "a") as fp:
            fp.write(udev_line)
        # is slave docker is not bound with host container os's /dev, add devices binding
        if not ("bind_dev" in slave and isinstance(slave["bind_dev"], bool) and slave["bind_dev"]):
            dockcomp_add_device(dockcomp, slave_name, "/dev/{}:/dev/{}".format(board_name, board_name))
        # setup serial tool to use over the serial I/F to DUT target
        use_conmux = uart["use_conmux"] if "use_conmux" in uart else False
        use_ser2net = uart["use_ser2net"] if "use_ser2net" in uart else False
        use_screen = uart["use_screen"] if "use_screen" in uart else False
        if (use_conmux and use_ser2net) or (use_conmux and use_screen) or (use_screen and use_ser2net):
            print("ERROR: Only one uart handler must be configured")
            sys.exit(1)
        if not use_conmux and not use_screen and not use_ser2net and not "connection_command" in board:
            use_ser2net = True
        # setup the conmux conf
        if use_conmux:
            conmuxline = template_conmux.substitute(board=board_name, baud=baud)
            device_line += template_device_conmux.substitute(board=board_name)
            with open("{}/conmux/{}.cf".format(workdir, board_name), "w") as fp:
                fp.write(conmuxline)
        # setup the ser2net conf (default)
        if use_ser2net:
            if not slave_name in ser2net_ports:
                ser2net_ports[slave_name] = ser2net_port_start
                with open("{}/ser2net.conf".format(workdir), "a") as fp:
                    fp.write("DEFAULT:max-connections:10\n")
            ser2net_line = "{}:telnet:600:/dev/{}:{} 8DATABITS NONE 1STOPBIT".format(ser2net_ports[slave_name], board_name, baud)
            if "ser2net_options" in uart:
                for ser2net_option in uart["ser2net_options"]:
                    ser2net_line += " {}".format(ser2net_option)
            device_line += template_device_ser2net.substitute(port=ser2net_ports[slave_name])
            ser2net_ports[slave_name] += 1
            with open("{}/ser2net.conf".format(workdir), "a") as fp:
                fp.write(ser2net_line + " banner\n")
        # setup screen conf
        if use_screen:
            device_line += template_device_screen.substitute(board=board_name)
            with open("{}/lava-screen.conf".format(workdir), "a") as fp:
                fp.write("{}\n".format(board_name))

    # setup the connection method of the target DUT board
    if "connection_command" in board:
        connection_command = board["connection_command"]
        device_line += template_device_connection_command.substitute(connection_command=connection_command)

    if "uboot_ipaddr" in board:
        device_line += "{{%% set uboot_ipaddr_cmd = 'setenv ipaddr {}' %%}}\n".format(board["uboot_ipaddr"])

    if "uboot_macaddr" in board:
        device_line += "{{% set uboot_set_mac = true %}}"
        device_line += "{{%% set uboot_mac_addr = '{}' %%}}\n".format(board["uboot_macaddr"])

    if "fastboot_serial_number" in board:
        fserial = board["fastboot_serial_number"]
        device_line += "{{%% set fastboot_serial_number = '{}' %%}}".format(fserial)

    if "tags" in board:
        tagdir = "{}/tags/".format(workdir)
        with open("{}/{}".format(tagdir, board_name), 'w') as ftag:
            for tag in board["tags"]:
                ftag.write("{}\n".format(tag))

    if "tags" in slave:
        tagdir = "{}/tags/".format(workdir)
        with open("{}/{}".format(tagdir, board_name), 'a') as ftag:
            for tag in slave["tags"]:
                ftag.write("{}\n".format(tag))

    if "aliases" in board:
        aliases_dir = "{}/aliases/".format(workdir)
        with open("{}/{}".format(aliases_dir, board["type"]), 'a') as falias:
            for alias in board["aliases"]:
                falias.write("{}\n".format(alias))

    if "user" in board:
        with open("{}/deviceinfo/{}".format(workdir, board_name), 'w') as deviceinfo:
            deviceinfo.write("DEVICE_USER={}\n".format(board["user"]))

    if "group" in board:
        if "user" in board:
                print("user and group are exclusive")
                sys.exit(1)
        with open("{}/deviceinfo/{}".format(workdir, board_name), 'w') as deviceinfo:
            deviceinfo.write("DEVICE_GROUP={}\n".format(board["group"]))

    if "custom_option" in board:
        if type(board["custom_option"]) == list:
            for coption in board["custom_option"]:
                device_line += "{{%% {} %%}}\n".format(coption)
        else:
            for line in board["custom_option"].splitlines():
                device_line += "{{%% {} %%}}\n".format(line)

    if not os.path.isdir(device_basepath):
        os.mkdir(device_basepath)
    if not os.path.isdir(devices_workerpath):
        os.mkdir(devices_workerpath)
    with open("{}/{}.jinja2".format(devices_workerpath, board_name), "w") as fp:
        fp.write(device_line)
    #end for board



def parse_jenkins(dockcomp, jenkins):
    """
    Parse Jenkins Configurations from ci-box-conf.yaml
    """
    workdir = "./ci-box-jenkins"
    keywords_jenkins = [ "version", "username", "password", "http_port",
    "agent_port", "extra_packages", "plugins", "ports", "volumes", "environment" ]

    for keyword in jenkins:
        if not keyword in keywords_jenkins:
            print("WARNING: unknown keyword {}".format(keyword))
    name = "jenkins"
    print("Parsing {}".format(name))

    dockcomp["services"][name] = {}
    dockcomp["services"][name]["container_name"] = name
    dockcomp["services"][name]["hostname"] = name
    dockcomp["services"][name]["image"] = "tn/{}".format(name)
    # extends:
    #      file: ./ci-box-jenkins/docker-compose.yml
    #      service: jenkins
    dockcomp["services"][name]["extends"] = {}
    dockcomp["services"][name]["extends"]["file"] = "{}/docker-compose.yml".format(workdir)
    dockcomp["services"][name]["extends"]["service"] = "jenkins"
    # build: overriding some args settings
    dockcomp["services"][name]["build"] = {}
    dockcomp["services"][name]["build"]["context"] = workdir
    dockcomp["services"][name]["build"]["args"] = {}
    dockcomp["services"][name]["build"]["args"]["version"] = jenkins["version"]
    dockcomp["services"][name]["build"]["args"]["http_port"] = jenkins["http_port"]
    dockcomp["services"][name]["build"]["args"]["agent_port"] = jenkins["agent_port"]
    dockcomp["services"][name]["build"]["args"]["extra_packages"] = jenkins["extra_packages"]
    dockcomp["services"][name]["build"]["args"]["plugins"] = jenkins["plugins"]
    # docker-compose's usual ports, volumes and environment overrides
    if isinstance(jenkins["ports"], list) and len(jenkins["ports"]) > 0:
        dockcomp["services"][name]["ports"] = jenkins["ports"]
    if isinstance(jenkins["volumes"], list) and len(jenkins["volumes"]) > 0:
        dockcomp["services"][name]["volumes"] = jenkins["volumes"]
    if isinstance(jenkins["environment"], dict) and len(jenkins["environment"]) > 0:
        dockcomp["services"][name]["environment"] = {}
        dockcomp["services"][name]["environment"].update(jenkins["environment"])
    # end for jenkins

def parse_builder(dockcomp, builder):
    """
    Parse Builders Configurations for jenkins from ci-box-conf.yaml
    """
    workdir = "./ci-box-builders/builder"
    keywords_builder = [ "name", "username", "password", "toolchain", "extra_pkgs",
    "sshd_port", "ports", "volumes", "environment" ]

    for keyword in builder:
        if not keyword in keywords_builder:
            print("WARNING: unknown keyword {}".format(keyword))
    name = "{}-builder".format(builder["name"])
    print("Parsing {}".format(name))

    dockcomp["services"][name] = {}
    dockcomp["services"][name]["container_name"] = name
    dockcomp["services"][name]["hostname"] = name
    dockcomp["services"][name]["image"] = "tn/{}".format(name)
    # extends:
    #      file: ./ci-box-builders/builder/docker-compose.yml
    #      service: builder
    dockcomp["services"][name]["extends"] = {}
    dockcomp["services"][name]["extends"]["file"] = "{}/docker-compose.yml".format(workdir)
    dockcomp["services"][name]["extends"]["service"] = "builder"
    # build: overriding some args settings
    dockcomp["services"][name]["build"] = {}
    dockcomp["services"][name]["build"]["context"] = workdir
    dockcomp["services"][name]["build"]["args"] = {}
    if "username" in builder:
        dockcomp["services"][name]["build"]["args"]["builder_username"] = builder["username"]
    if "password" in builder:
        dockcomp["services"][name]["build"]["args"]["builder_password"] = builder["password"]
    if "toolchain" in builder:
        dockcomp["services"][name]["build"]["args"]["toolchain"] = builder["toolchain"]
    if "extra_pkgs" in builder:
        dockcomp["services"][name]["build"]["args"]["extra_pkgs"] = builder["extra_pkgs"]
    if "ssh_port" in builder:
        dockcomp["services"][name]["build"]["args"]["sshd_port"] = builder["ssh_port"]
    # end for builder



def parse_squad(dockcomp, squad):
    """
    Parse Squad Configurations for jenkins from ci-box-conf.yaml
    """
    workdir = "./ci-box-squad"
    keywords_squad = [ "version", "http_port", "extra_packages",
    "username", "password", "email", "token", "group", "projects",
    "lava_server", "lava_rpc_port", "lava_username", "lava_token",
    "ports", "volumes", "environment" ]
    for keyword in squad:
        if not keyword in keywords_squad:
            print("WARNING: unknown keyword {}".format(keyword))
    name = "squad"
    print("Parsing {}".format(name))

    dockcomp["services"][name] = {}
    dockcomp["services"][name]["container_name"] = name
    dockcomp["services"][name]["hostname"] = name
    dockcomp["services"][name]["image"] = "tn/{}".format(name)
    # extends:
    #      file: ./ci-box-lava-squad/docker-compose.yml
    #      service: squad
    dockcomp["services"][name]["extends"] = {}
    dockcomp["services"][name]["extends"]["file"] = "{}/docker-compose.yml".format(workdir)
    dockcomp["services"][name]["extends"]["service"] = "squad"
    # build: overriding some args settings
    dockcomp["services"][name]["build"] = {}
    dockcomp["services"][name]["build"]["context"] = workdir
    dockcomp["services"][name]["build"]["args"] = {}
    dockcomp["services"][name]["build"]["args"]["version"] = squad["version"]
    if "http_port" in squad:
        dockcomp["services"][name]["build"]["args"]["http_port"] = squad["http_port"]
    dockcomp["services"][name]["build"]["args"]["admin_username"] = squad["username"]
    dockcomp["services"][name]["build"]["args"]["admin_password"] = squad["password"]
    dockcomp["services"][name]["build"]["args"]["admin_email"] = squad["email"]
    dockcomp["services"][name]["build"]["args"]["admin_token"] = squad["token"]
    if "extra_packages" in squad:
        dockcomp["services"][name]["build"]["args"]["extra_packages"] = squad["extra_packages"]
    dockcomp["services"][name]["build"]["args"]["group"] = squad["group"]
    dockcomp["services"][name]["build"]["args"]["projects"] = squad["projects"]
    dockcomp["services"][name]["build"]["args"]["lava_server"] = squad["lava_server"]
    dockcomp["services"][name]["build"]["args"]["lava_rpc_port"] = squad["lava_rpc_port"]
    dockcomp["services"][name]["build"]["args"]["lava_username"] = squad["lava_username"]
    dockcomp["services"][name]["build"]["args"]["lava_token"] = squad["lava_token"]
    # docker-compose's usual ports, volumes and environment overrides
    if "ports" in squad and isinstance(squad["ports"], list) and len(squad["ports"]) > 0:
        dockcomp["services"][name]["ports"] = squad["ports"]
    if "volumes" in squad and isinstance(squad["volumes"], list) and len(squad["volumes"]) > 0:
        dockcomp["services"][name]["volumes"] = squad["volumes"]
    if "environment" in squad and isinstance(squad["environment"], dict) and len(squad["environment"]) > 0:
        dockcomp["services"][name]["environment"] = {}
        dockcomp["services"][name]["environment"].update(squad["environment"])
    # end for squad



def parse_healthcheck(dockcomp, health):
    """
    Parse Builders Configurations for jenkins from ci-box-conf.yaml
    """
    workdir = "./ci-box-fileserver"
    keywords_healthcheck = [ "http_port", "ftp_port", "root_path", "extra_packages",
    "ports", "volumes", "environment" ]
    for keyword in health:
        if not keyword in keywords_healthcheck:
            print("WARNING: unknown keyword {}".format(keyword))
    name = "healthcheck"
    print("Parsing {}".format(name))

    # added healthcheck hosts for lava-worker to fetch images/scripts
    dockcomp["services"][name] = {}
    dockcomp["services"][name]["container_name"] = name
    dockcomp["services"][name]["hostname"] = name
    dockcomp["services"][name]["image"] = "tn/{}".format(name)
    #extends:
    #    file: ./ci-box-fileserver/docker-compose.yml
    #    service: fileserver
    dockcomp["services"][name]["extends"] = {}
    dockcomp["services"][name]["extends"]["file"] = "{}/docker-compose.yml".format(workdir)
    dockcomp["services"][name]["extends"]["service"] = "fileserver"
    dockcomp["services"][name]["build"] = {}
    dockcomp["services"][name]["build"]["context"] = workdir
    dockcomp["services"][name]["build"]["args"] = {}
    #build:
    #   args:
    #       http_port: 80
    #       ftp_port: 21
    #       root: "/wwwroot"
    dockcomp["services"][name]["build"]["args"]["http_port"] = health["http_port"]
    dockcomp["services"][name]["build"]["args"]["ftp_port"] = health["ftp_port"]
    dockcomp["services"][name]["build"]["args"]["root_path"] = health["root_path"]
    if "extra_packages" in health:
        dockcomp["services"][name]["build"]["args"]["extra_packages"] = health["extra_packages"]
    if "ports" in health and isinstance(health["ports"], list):
        dockcomp["services"][name]["ports"] = health["ports"]
    else:
        dockcomp["services"][name]["ports"] = ["8080:8080"]
    if "volumes" in health and isinstance(health["volumes"], list):
        dockcomp["services"][name]["volumes"] = health["volumes"]
    if "environment" in health and isinstance(health["environment"], dict) and len(health["environment"]) > 0:
        dockcomp["services"][name]["environment"] = {}
        dockcomp["services"][name]["environment"].update(health["environment"])
    # end for healthcheck/fileserver



# main
def main():
    need_zmq_auth_gen = False
    with open(configs_yaml, "r") as fp:
        configs = yaml.safe_load(fp)

    zmq_auth_genlist = open("zmqauth/zmq_auth_gen/zmq_genlist", 'w')

    dockcomp = {}
    dockcomp["version"] = "2.0"
    dockcomp["services"] = {}

    # parse external postgresql database server setting from the ci-box-conf.yaml
    if "postgres" in configs:
        parse_database(dockcomp, configs["postgres"])

    # parse jenkins
    if "jenkins" in configs:
        parse_jenkins(dockcomp, configs["jenkins"])

    # parse builders for jenkins
    builders = {} if "builders" not in configs else configs["builders"]
    for builder in builders:
        parse_builder(dockcomp, builder)

    # parse healthcheck / images/scripts server
    if "healthcheck" in configs:
        parse_healthcheck(dockcomp, configs["healthcheck"])

    # parse squad
    if "squad" in configs:
        parse_squad(dockcomp, configs["squad"])

    # parse lava masters from the ci-box-conf.yaml
    masters = {} if "masters" not in configs else configs["masters"]
    for index, master in enumerate(masters, start=0):
        parse_master(dockcomp, index, master)

    # parse lava slaves from the ci-box-conf.yaml
    slaves = {} if "slaves" not in configs else configs["slaves"]
    for index, slave in enumerate(slaves, start=0):
        # pass masters into slave, so it can find corresponding find master
        masters = configs["masters"] if "masters" in configs else {}
        parse_slave(dockcomp, index, slave, masters)

    # parse test boards from the ci-box-conf.yaml
    boards = {} if "boards" not in configs else configs["boards"]
    for board in boards:
        parse_board(dockcomp, board, slaves)

    # setup ser2net ports for DUT
    # Do ser2net ports need to be available on host, then check expose_ports
    for slave_name in ser2net_ports:
        expose_ser2net = False
        for slave in configs["slaves"]:
            if slave["name"] == slave_name:
                if not "host" in slave:
                    host = "local"
                else:
                    host = slave["host"]
                if "expose_ser2net" in slave:
                    expose_ser2net = slave["expose_ser2net"]
                if "export_ser2net" in slave:
                    print("export_ser2net is deprecated, please use expose_ser2net")
                    expose_ser2net = slave["export_ser2net"]
        if not expose_ser2net:
            continue
        print("Add ser2net ports for {} ({}) {}-{}".format(slave_name, host, ser2net_port_start, ser2net_ports[slave_name]))

        ser2net_port_max = ser2net_ports[slave_name] - 1
        dockcomp["services"][slave_name]["ports"].append("{}-{}:{}-{}".format(ser2net_port_start, ser2net_port_max, ser2net_port_start, ser2net_port_max))


    # setup zmq authorization for lava server-worker communications
    zmq_auth_genlist.close()
    if need_zmq_auth_gen:
        print("Gen ZMQ auth files")
        subprocess.check_call(["./zmqauth/zmq_auth_fill.sh"], stdin=None)

    # dump ./docker-compose.yml
    with open("./docker-compose.yml", 'w') as f:
        yaml.dump(dockcomp, f)

    # dump ./Makefile
    containers = list(serv for serv in dockcomp["services"])
    builders = list(name for name in containers if "builder" in name)
    servers = list(name for name in containers if "builder" not in name)
    with open("./Makefile", 'w') as f:
        f.write(template_makefile.substitute(containers=" ".join(["tn/{}".format(d) for d in containers]), dockers=" ".join(servers), builders=" ".join(builders)))



if len(sys.argv) > 1:
    if sys.argv[1] == '-h' or sys.argv[1] == '--help':
        usage()
        sys.exit(0)
    configs_yaml = sys.argv[1]

if __name__ == "__main__":
    main()
